{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530b3772",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "## Approach\n",
    "- Build the tree by defining best split feature and best split threshold for each node using Entropy and Information Gain.\n",
    "- Label of a leaf node is the label of majority of samples in that leaf node\n",
    "<img src=\"pics/tree.pic5.png\" width=\"700\">\n",
    "<img src=\"pics/tree.pic6.png\" width=\"700\">\n",
    "## Initial Example: Walking to work?\n",
    " Walking to work? | Rule-based tree\n",
    "- | - \n",
    "<img src=\"pics/tree.pic1.png\" width=\"300\"> | <img src=\"pics/tree.pic2.png\" width=\"400\">\n",
    "\n",
    "## Entropy: 0 -> 1\n",
    "$Entropy = 0$: best case, a label can be defined.\\\n",
    "$Entropy = 1$: worst case, a label can not be defined.\n",
    "<img src=\"pics/tree.pic3.png\" width=\"600\" >\n",
    "\n",
    "## Information Gaining\n",
    "<img src=\"pics/tree.pic4.png\" width=\"500\" >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f84abfc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T00:14:12.171149Z",
     "start_time": "2022-02-21T00:14:12.159214Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    \n",
    "    class Node:\n",
    "        def __init__(self, feature_idx=None, value=None, left=None, right=None,*,label=None):\n",
    "            self.feature_idx = feature_idx\n",
    "            self.value = value\n",
    "            self.left_node = left\n",
    "            self.right_node = right\n",
    "            self.label = label\n",
    "\n",
    "            \n",
    "    def __init__(self, min_split=2, max_depth=100, n_feature = None):\n",
    "        self.min_split=2\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feature = n_feature\n",
    "        self.root  = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        _ , total_feature = X.shape\n",
    "        self.n_feature = total_feature if self.n_feature == None else self.n_feature\n",
    "        self.root = self.make_node(X,y)\n",
    "        \n",
    "         \n",
    "    def make_node(self, X, y, depth=0):\n",
    "        n_sample, total_feature = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        \n",
    "        #checking leaf node\n",
    "        if (depth >= self.max_depth) or n_labels==1 or n_sample < self.min_split:\n",
    "\n",
    "            common_label = Counter(y).most_common(1)[0][0]\n",
    "\n",
    "            return Tree.Node(label=common_label)\n",
    "            \n",
    "        #if not leaf, then make parent and child nodes\n",
    "        feature_idxs = np.random.choice(total_feature, self.n_feature, False) \n",
    "        #take randomly some columns out of the total # column of X \n",
    "        #getting the random subdataset\n",
    "        \n",
    "        \n",
    "        #initialize optimized variables\n",
    "        best_gaining = 0\n",
    "        split_feature_idx = None\n",
    "        split_value = None\n",
    "        \n",
    "        #start looping through random selected features, to find the best feature with best threshold\n",
    "        for feature_idx in feature_idxs:\n",
    "            feature = X[:,feature_idx]\n",
    "            unique_values= np.unique(feature)\n",
    "            #for each feature, loop through unique thresholds, to find the best threshold\n",
    "            for unique_value in unique_values:\n",
    "                gaining = self.info_gain(y, feature, unique_value)\n",
    "                if gaining >= best_gaining:\n",
    "                    best_gaining = gaining\n",
    "                    split_feature_idx = feature_idx\n",
    "                    split_value = unique_value\n",
    "                \n",
    "        #spliting sample\n",
    "        left_idxs =  np.argwhere(X[:,split_feature_idx] <= split_value).flatten()\n",
    "        right_idxs = np.argwhere(X[:,split_feature_idx] > split_value).flatten()\n",
    "        \n",
    "        left_sample_X = X[left_idxs,:]\n",
    "        left_sample_y = y[left_idxs]\n",
    "        right_sample_X = X[right_idxs,:]\n",
    "        right_sample_y = y[right_idxs]\n",
    "        \n",
    "        left_node = self.make_node(left_sample_X, left_sample_y, depth+1)\n",
    "        right_node = self.make_node(right_sample_X, right_sample_y, depth+1)\n",
    "        \n",
    "        return Tree.Node(split_feature_idx, split_value, left_node, right_node)\n",
    "      \n",
    "    \n",
    "    def entropy(self, y):\n",
    "        py = np.bincount(y)/len(y)\n",
    "        py = np.array([p for p in py if p>0]) # for extreme cases of label has no count, log2(0) -> inf\n",
    "        E = np.sum(-py*np.log2(py)) \n",
    "        #E = np.sum([-p * np.log2(p) for p in py])\n",
    "        return E     \n",
    "    \n",
    "    def info_gain(self, y, feature, split_value):\n",
    "        parent_E = self.entropy(y)\n",
    "        child1_idxs = np.argwhere(feature <= split_value).flatten()\n",
    "        child2_idxs = np.argwhere(feature > split_value).flatten()\n",
    "        \n",
    "        \n",
    "        child1_E = self.entropy(y[child1_idxs])\n",
    "        child2_E = self.entropy(y[child2_idxs])\n",
    "        gaining = parent_E - (len(child1_idxs)*child1_E + len(child2_idxs)*child2_E)/len(y)\n",
    "        return gaining\n",
    "        \n",
    "    def traverse(self, x, node):\n",
    "        if node.label != None:\n",
    "            return node.label\n",
    "        if x[node.feature_idx] > node.value:\n",
    "            return self.traverse(x, node.right_node)\n",
    "        else:\n",
    "            return self.traverse(x, node.left_node)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.traverse(x, self.root) for x in X])\n",
    "        \n",
    "    def accuracy(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        score = np.sum(y_hat==y)/len(y)\n",
    "        return f'{score:.3f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b651ffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T00:14:20.984133Z",
     "start_time": "2022-02-21T00:14:19.296189Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test: \n",
      "\t[1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 0]\n",
      "y_hat: \n",
      "\t[1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0\n",
      " 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
      " 1 1 0]\n",
      "Accuracy Score: 0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "model = Tree()\n",
    "model.fit(X_train, y_train)\n",
    "print(f'y_test: \\n\\t{y_test}')\n",
    "print(f'y_hat: \\n\\t{model.predict(X_test)}')\n",
    "print(f'Accuracy Score: {model.accuracy(X_test, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
